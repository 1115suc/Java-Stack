# LangChain4j

## 一、聊天与语言模型

### 1.`ChatRequest` 与 `ChatResponse`

- 如果你想自定义请求（例如指定模型名称、temperature、tools、JSON schema 等），可以使用 chat(ChatRequest) 方法：

```java
    ChatRequest chatRequest = ChatRequest.builder()
        .messages(...)
        .modelName(...)
        .temperature(...)
        .topP(...)
        .topK(...)
        .frequencyPenalty(...)
        .presencePenalty(...)
        .maxOutputTokens(...)
        .stopSequences(...)
        .toolSpecifications(...)
        .toolChoice(...)
        .responseFormat(...)
        .parameters(...) // 你也可以一次性设置通用或提供商特定的参数
        .build();
    
    ChatResponse chatResponse = chatModel.chat(chatRequest);
```

### 2.`ChatMessage` 的类型

- `UserMessage`: 这是来自用户的消息
- `SystemMessage`: 这是系统消息，通常用于提供上下文信息
- `AiMessage`: 这是 AI 生成的消息，用于响应输入的消息
  - text()：文本内容
  - thinking()：推理/思考内容
  - toolExecutionRequests()：执行工具的请求
  - attributes()：额外属性，通常是提供商特定的
- `CustomMessage`: 这是一个自定义消息，可以包含任意属性 (目前仅 Ollama 支持)

### 3.多个`ChatMessage` 

- LLM 本质上是无状态的，它们不会维护对话的上下文状态，所以需要自行维护多个 'ChatMessage' 对话上下文。

```java
    UserMessage firstUserMessage = UserMessage.from("Hello, my name is Klaus");
    AiMessage firstAiMessage = model.chat(firstUserMessage).aiMessage(); // Hi Klaus, how can I help you?
    UserMessage secondUserMessage = UserMessage.from("What is my name?");
    AiMessage secondAiMessage = model.chat(firstUserMessage, firstAiMessage, secondUserMessage).aiMessage(); // Klaus
```








